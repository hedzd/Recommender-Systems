{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csyQrFtNCznw"
   },
   "source": [
    "# Problem Statement\n",
    "In this assignment we are using the MovieLens 1M dataset which contains 1000208 ratings given to about 3706 movies by 6040 users. Our aim is to implement three recommendation algorithms to estimate the rating a given user would give to a given movie. We will evaluate the accuracy of these algorithms with the Root Mean Squared Error (RMSE), and the Mean Absolute Error (MAE). We are using 5-fold cross-validation and report the RMSE and MAE on average of 5-folds for test dataset to obtain reliable results.  \n",
    "The three algorithmes we implemented are:  \n",
    "1. Naive Approaches\n",
    "2. The UV matrix decomposition\n",
    "3. The Matrix Factorization   \n",
    "\n",
    "We will dicuss details of each algorithms and its implementation in three parts in this notebook.\n",
    "\n",
    "It may happen that some users or movies that appear in a test set would not appear in the training set, we handled this situation on each algorithm differently which we will dicuss it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJICgXx8ID6X"
   },
   "source": [
    "## Importing requirments and preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2166,
     "status": "ok",
     "timestamp": 1698002899721,
     "user": {
      "displayName": "Hedieh Pourghasem",
      "userId": "11017133499432378908"
     },
     "user_tz": -120
    },
    "id": "ruqxC70FHYEW",
    "outputId": "fec56cda-3f76-43d7-835e-cc6805be6adc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-22 19:28:17--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5917549 (5.6M) [application/zip]\n",
      "Saving to: ‘ml-1m.zip’\n",
      "\n",
      "ml-1m.zip           100%[===================>]   5.64M  10.6MB/s    in 0.5s    \n",
      "\n",
      "2023-10-22 19:28:18 (10.6 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
      "\n",
      "Archive:  ml-1m.zip\n",
      "   creating: ml-1m/\n",
      "  inflating: ml-1m/movies.dat        \n",
      "  inflating: ml-1m/ratings.dat       \n",
      "  inflating: ml-1m/README            \n",
      "  inflating: ml-1m/users.dat         \n"
     ]
    }
   ],
   "source": [
    "# Downloading and preparing the dataset\n",
    "!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "!unzip ml-1m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1584,
     "status": "ok",
     "timestamp": 1698002903330,
     "user": {
      "displayName": "Hedieh Pourghasem",
      "userId": "11017133499432378908"
     },
     "user_tz": -120
    },
    "id": "AkhwknWbHeN2"
   },
   "outputs": [],
   "source": [
    "# Importing requirments\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2Jr9q0UII2-"
   },
   "source": [
    "### RATINGS FILE DESCRIPTION\n",
    "\n",
    "All ratings are contained in the file \"ratings.dat\" and are in the\n",
    "following format:\n",
    "\n",
    "UserID::MovieID::Rating::Timestamp\n",
    "\n",
    "- UserIDs range between 1 and 6040\n",
    "- MovieIDs range between 1 and 3952\n",
    "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
    "- Timestamp is represented in seconds since the epoch as returned by time(2)\n",
    "- Each user has at least 20 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 5898,
     "status": "ok",
     "timestamp": 1698002911706,
     "user": {
      "displayName": "Hedieh Pourghasem",
      "userId": "11017133499432378908"
     },
     "user_tz": -120
    },
    "id": "KhGTuHxEH1zn",
    "outputId": "977a5817-2e19-45d3-c8bb-3b1d7f5ca7bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-05e5c6dcba11>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv('/content/ml-1m/ratings.dat', sep=\"::\", header=0, names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ff1afc71-2ad4-40c5-ac2a-2540631866ec\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>978302039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>978300719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "      <td>978301368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>595</td>\n",
       "      <td>5</td>\n",
       "      <td>978824268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff1afc71-2ad4-40c5-ac2a-2540631866ec')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ff1afc71-2ad4-40c5-ac2a-2540631866ec button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ff1afc71-2ad4-40c5-ac2a-2540631866ec');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-741c7438-1763-48cd-8b24-a9cc1b39136e\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-741c7438-1763-48cd-8b24-a9cc1b39136e')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-741c7438-1763-48cd-8b24-a9cc1b39136e button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1      661       3  978302109\n",
       "1       1      914       3  978301968\n",
       "2       1     3408       4  978300275\n",
       "3       1     2355       5  978824291\n",
       "4       1     1197       3  978302268\n",
       "5       1     1287       5  978302039\n",
       "6       1     2804       5  978300719\n",
       "7       1      594       4  978302268\n",
       "8       1      919       4  978301368\n",
       "9       1      595       5  978824268"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading ratings.dat file which contains all given ratings\n",
    "df = pd.read_csv('/content/ml-1m/ratings.dat', sep=\"::\", header=0, names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gFte4yuGeNf"
   },
   "source": [
    "# 1. Naive Approaches\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPqpX1bzsTF"
   },
   "source": [
    "## Linear combination of the three averages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jx8sLa4lG4ii"
   },
   "source": [
    "## Description of algorithm:  \n",
    "In this algorithm we use the global average rating, the average rating per item noted as R_item(User, Item) and the average rating per user noted as R_user(User, Item).\n",
    "The goal is to estimate the rating for a given “active user” to the given item, R(User, Item).\n",
    "\n",
    "We can estimate the rating using four different naive aproach:\n",
    "  1. Using global average:  \n",
    "  We just estimate the average of all ratings for any given user and movie\n",
    "  2. Using user average:  \n",
    "  We estimate the rating of a given user to a given movie based on all other average ratings that the user had given in our dataset.\n",
    "  3. Using movie average:  \n",
    "  We estimate the rating of a given user to a given movie based on all other average ratings that the movie had recieved based on all available data in our dataset.\n",
    "  4. linear combination of the three averages:  \n",
    "  In this approuch we approximate the R(User, Item) as a linear combination of R_item(User, Item) and R_user(User, Item). Using the following formula:  \n",
    "  R(User, Item)= α * R_user(User, Item) + β * R_item(User, Item) + γ.  \n",
    "  For finding “optimal” values for α, β and γ we can solve this problem as a least squares regression problem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48h29Z6NG7v5"
   },
   "source": [
    "## Details of implementation:  \n",
    "\n",
    "For implementing 5-fold cross validation we used **KFold module from sklearn** which gives us indices of samples in train and test dataset for each fold. We are using a loop in which we iterate over five folds of dataset and in each iteration we train and evaluate a model with our naive approach. In each of approaches we calculate the average values which are needed. After that we enter the evaluation phase in which we calculate predicted values. After calculating the predicted values for each test data sample, we need to do a post process on results. For this porpus we wrote a function **post_process(results)** which round each estimated rating to the nearest integer and also keep results in a range of [1,5].   \n",
    "After doing the post process, we used **mean_squared_error()** and **mean_absolute_error()** functions from sklearn to calculate RMSE amd MAE.\n",
    "\n",
    "Finally we report the RMSE and MAE for each model on each fold along with the final RMSE and MAE on total of 5 folds.\n",
    "\n",
    "***Handling gaps in numbering:*** In this algorithm the numbering of userIDs and movieIDs does not influence any calculation, so there is no need to to something about it. We can do renumbering as we did for matrix factorization part, but it will have no influence on final results of the algorithm.\n",
    "\n",
    "***Handling unseen data:*** We are using average of the overal ratings as a fall back for all four approaches. So whenever it comes to an unseen user or an unssen movie we just use the average of all ratings in prediction formula.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REndoTGm1kC3"
   },
   "source": [
    "### linear combination of the three averages:\n",
    "\n",
    "#### **Some implementation details:**\n",
    "For implementation of this algorithm we first need to calculate R_user(User, Item) for each user and R_item(User, Item) for each movie, for this porpus we wrote a function **get_R(df, column)** which calculate the average rating per item, the average rating per user. When column = 'UserID' is passed to it, it returns R_user(User, Item) and a map of UserID to mean of ratings all ratings this user have given to different movies. In the same way when column = 'MovieID' is passed to it, It returns R_item(User, Item) and a map of MovieID to mean of ratings all ratings this movie have gotten from all users.\n",
    "\n",
    "In training phase we calculate R_item(User, Item) and R_user(User, Item) on train dataset. After that we form the linear equation using **np.vstack([R_user_train, R_item_train, np.ones(R_item_train.shape)]).T** then we use **np.linalg.lstsq()** to find optimal values for α, β, and γ and finish the training.  \n",
    "\n",
    "As we find our three optimal parameters we can start the evaluation phase. In this part we predict a rating for each given user and movie in test dataset using our trained parameters and the linear formula. For this calculation we need to calculate average values R_user(User, Item) and R_item(User, Item) on test dataset. Then we use these average values along with trained parameters to calculate predicted value using the linear fomula of this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1698002911706,
     "user": {
      "displayName": "Hedieh Pourghasem",
      "userId": "11017133499432378908"
     },
     "user_tz": -120
    },
    "id": "lNaWwQC6Ipxz"
   },
   "outputs": [],
   "source": [
    "# A function for calculating R_item(User, Item) and R_user(User, Item)\n",
    "def get_R(df, column):\n",
    "  R_map = {}\n",
    "  for user in np.unique(df[column]):\n",
    "    R_map[user] = np.mean(df[df[column] == user]['Rating'])\n",
    "  R = np.array([R_map[df[column][i]] for i in df.index])\n",
    "\n",
    "  return R, R_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1698002911706,
     "user": {
      "displayName": "Hedieh Pourghasem",
      "userId": "11017133499432378908"
     },
     "user_tz": -120
    },
    "id": "rfX8k4gEIraN"
   },
   "outputs": [],
   "source": [
    "# A function for post processing\n",
    "def post_process(results):\n",
    "  return np.clip(np.round(results), 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113290,
     "status": "ok",
     "timestamp": 1698003398271,
     "user": {
      "displayName": "Hedieh Pourghasem",
      "userId": "11017133499432378908"
     },
     "user_tz": -120
    },
    "id": "SC4Xe6DmCSqH",
    "outputId": "308fa42f-5412-4b75-d497-4b62e6e1ecaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for fold # 1 :  0.9371981883804401\n",
      "MAE for fold # 1 :  0.6948590795932854\n",
      "RMSE for fold # 2 :  0.9345737395147019\n",
      "MAE for fold # 2 :  0.6944641625258696\n",
      "RMSE for fold # 3 :  0.9327141300326931\n",
      "MAE for fold # 3 :  0.6944241709241059\n",
      "RMSE for fold # 4 :  0.936667983063472\n",
      "MAE for fold # 4 :  0.6963772426652536\n",
      "RMSE for fold # 5 :  0.937707769907169\n",
      "MAE for fold # 5 :  0.6964372303677746\n",
      "Mean RMSE on all 5 folds:  0.9357723621796952\n",
      "Mean MAE on all 5 folds:  0.6953123772152578\n"
     ]
    }
   ],
   "source": [
    "### Train and Evaluation ###\n",
    "\n",
    "# Implementing 5-fold cross validation\n",
    "number_of_folds = 5\n",
    "kf = KFold(n_splits=number_of_folds, shuffle=True, random_state=42)\n",
    "\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(df)):\n",
    "\n",
    "  train_data = df.iloc[train_idx]\n",
    "  test_data = df.iloc[test_idx]\n",
    "\n",
    "  overall_train_rating = train_data['Rating'].mean()\n",
    "\n",
    "  ### Train phase ###\n",
    "  R_user_train, R_user_map_train = get_R(train_data, 'UserID')\n",
    "  R_item_train, R_item_map_train = get_R(train_data, 'MovieID')\n",
    "\n",
    "  # using np.linalg.lstsq() to solve this “least squares regression problem”\n",
    "  A = np.vstack([R_user_train, R_item_train, np.ones(R_item_train.shape)]).T\n",
    "  alpha, beta, gamma = np.linalg.lstsq(A, train_data['Rating'], rcond=None)[0]\n",
    "\n",
    "  ### Evaluation phase ###\n",
    "  # predict rating based on this formula:  alpha * R_user(User, Item) + beta * R_item(User, Item) + gamma\n",
    "  predicteds = [alpha * R_user_map_train.get(row.UserID, overall_train_rating) + beta * R_item_map_train.get(row.MovieID, overall_train_rating) + gamma for row in test_data.itertuples()]\n",
    "  predicteds_normalized = post_process(predicteds)\n",
    "\n",
    "  # calculate RMSE and MAE of final model on test data\n",
    "  rmse = mean_squared_error(test_data['Rating'], predicteds_normalized)\n",
    "  mae = mean_absolute_error(test_data['Rating'], predicteds_normalized)\n",
    "\n",
    "  rmse_list.append(rmse)\n",
    "  mae_list.append(mae)\n",
    "  print(f'RMSE for fold #', fold_idx+1, ': ', rmse)\n",
    "  print(f'MAE for fold #', fold_idx+1, ': ', mae)\n",
    "\n",
    "### Reporting the average error of five models ###\n",
    "print(f'Mean RMSE on all 5 folds: ', np.mean(rmse_list))\n",
    "print(f'Mean MAE on all 5 folds: ', np.mean(mae_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9RiwzyX1m1T"
   },
   "source": [
    "### Using movie average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5959,
     "status": "ok",
     "timestamp": 1698003118829,
     "user": {
      "displayName": "Hedieh Pourghasem",
      "userId": "11017133499432378908"
     },
     "user_tz": -120
    },
    "id": "YHSWG46T1s8h",
    "outputId": "eb6ba9a1-8474-42ee-a5b7-94aea4c7f121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for fold # 1 :  1.0368722568260664\n",
      "MAE for fold # 1 :  0.7510722748222873\n",
      "RMSE for fold # 2 :  1.0377720678657483\n",
      "MAE for fold # 2 :  0.7505723798002419\n",
      "RMSE for fold # 3 :  1.0369672368802552\n",
      "MAE for fold # 3 :  0.7508773157636897\n",
      "RMSE for fold # 4 :  1.0377522607865388\n",
      "MAE for fold # 4 :  0.7501312230992646\n",
      "RMSE for fold # 5 :  1.0390919861428407\n",
      "MAE for fold # 5 :  0.7517108992656505\n",
      "Mean RMSE on all 5 folds:  1.03769116170029\n",
      "Mean MAE on all 5 folds:  0.7508728185502268\n"
     ]
    }
   ],
   "source": [
    "### Train and Evaluation ###\n",
    "\n",
    "# Implementing 5-fold cross validation\n",
    "number_of_folds = 5\n",
    "kf = KFold(n_splits=number_of_folds, shuffle=True, random_state=42)\n",
    "\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(df)):\n",
    "\n",
    "  train_data = df.iloc[train_idx]\n",
    "  test_data = df.iloc[test_idx]\n",
    "\n",
    "  grouped_rating = train_data.groupby('MovieID')['Rating'].mean()\n",
    "  overall_train_rating = train_data['Rating'].mean()\n",
    "\n",
    "  ### No Train phase needed ###\n",
    "\n",
    "  ### Evaluation phase ###\n",
    "\n",
    "  # predict rating based on movie's average already rated ratings\n",
    "  predicteds = [grouped_rating.get(row.MovieID, overall_train_rating) for row in test_data.itertuples()]\n",
    "  predicteds_normalized = post_process(predicteds)\n",
    "\n",
    "  # calculate RMSE and MAE of final model on test data\n",
    "  rmse = mean_squared_error(test_data['Rating'], predicteds_normalized)\n",
    "  mae = mean_absolute_error(test_data['Rating'], predicteds_normalized)\n",
    "\n",
    "  rmse_list.append(rmse)\n",
    "  mae_list.append(mae)\n",
    "  print(f'RMSE for fold #', fold_idx+1, ': ', rmse)\n",
    "  print(f'MAE for fold #', fold_idx+1, ': ', mae)\n",
    "\n",
    "### Reporting the average error of five models ###\n",
    "print(f'Mean RMSE on all 5 folds: ', np.mean(rmse_list))\n",
    "print(f'Mean MAE on all 5 folds: ', np.mean(mae_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHAhUGCk1tcv"
   },
   "source": [
    "### Using user average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6233,
     "status": "ok",
     "timestamp": 1698003140851,
     "user": {
      "displayName": "Hedieh Pourghasem",
      "userId": "11017133499432378908"
     },
     "user_tz": -120
    },
    "id": "dNITANjf1wJq",
    "outputId": "d47b7d61-5fc5-44b5-9cf3-5fd416020d1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for fold # 1 :  1.1506383659431518\n",
      "MAE for fold # 1 :  0.7925935553533758\n",
      "RMSE for fold # 2 :  1.1563971565971145\n",
      "MAE for fold # 2 :  0.79451315223803\n",
      "RMSE for fold # 3 :  1.1519730856520132\n",
      "MAE for fold # 3 :  0.7930484598234371\n",
      "RMSE for fold # 4 :  1.1563429496953124\n",
      "MAE for fold # 4 :  0.7952869661719347\n",
      "RMSE for fold # 5 :  1.1582575572007738\n",
      "MAE for fold # 5 :  0.7963617458421024\n",
      "Mean RMSE on all 5 folds:  1.1547218230176732\n",
      "Mean MAE on all 5 folds:  0.794360775885776\n"
     ]
    }
   ],
   "source": [
    "### Train and Evaluation ###\n",
    "\n",
    "# Implementing 5-fold cross validation\n",
    "number_of_folds = 5\n",
    "kf = KFold(n_splits=number_of_folds, shuffle=True, random_state=42)\n",
    "\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(df)):\n",
    "\n",
    "  train_data = df.iloc[train_idx]\n",
    "  test_data = df.iloc[test_idx]\n",
    "\n",
    "  grouped_rating = train_data.groupby('UserID')['Rating'].mean()\n",
    "  overall_train_rating = train_data['Rating'].mean()\n",
    "\n",
    "  ### No Train phase needed ###\n",
    "\n",
    "  ### Evaluation phase ###\n",
    "\n",
    "  # predict rating based on user's average already rated ratings\n",
    "  predicteds = [grouped_rating.get(row.UserID, overall_train_rating) for row in test_data.itertuples()]\n",
    "  predicteds_normalized = post_process(predicteds)\n",
    "\n",
    "  # calculate RMSE and MAE of final model on test data\n",
    "  rmse = mean_squared_error(test_data['Rating'], predicteds_normalized)\n",
    "  mae = mean_absolute_error(test_data['Rating'], predicteds_normalized)\n",
    "\n",
    "  rmse_list.append(rmse)\n",
    "  mae_list.append(mae)\n",
    "  print(f'RMSE for fold #', fold_idx+1, ': ', rmse)\n",
    "  print(f'MAE for fold #', fold_idx+1, ': ', mae)\n",
    "\n",
    "### Reporting the average error of five models ###\n",
    "print(f'Mean RMSE on all 5 folds: ', np.mean(rmse_list))\n",
    "print(f'Mean MAE on all 5 folds: ', np.mean(mae_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koLkXQl01wgu"
   },
   "source": [
    "### Using global average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1578,
     "status": "ok",
     "timestamp": 1698003234652,
     "user": {
      "displayName": "Hedieh Pourghasem",
      "userId": "11017133499432378908"
     },
     "user_tz": -120
    },
    "id": "CL_PRb3515F_",
    "outputId": "04a38a0b-2e81-439e-b78b-e11d0d49aa49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for fold # 1 :  1.4251957089011307\n",
      "MAE for fold # 1 :  0.8714719908819148\n",
      "RMSE for fold # 2 :  1.4224262904789995\n",
      "MAE for fold # 2 :  0.8707621399506104\n",
      "RMSE for fold # 3 :  1.4189320242749022\n",
      "MAE for fold # 3 :  0.8693274412373402\n",
      "RMSE for fold # 4 :  1.4254277873036028\n",
      "MAE for fold # 4 :  0.8719612479441714\n",
      "RMSE for fold # 5 :  1.4230382771531835\n",
      "MAE for fold # 5 :  0.8712813873156003\n",
      "Mean RMSE on all 5 folds:  1.4230040176223635\n",
      "Mean MAE on all 5 folds:  0.8709608414659276\n"
     ]
    }
   ],
   "source": [
    "### Train and Evaluation ###\n",
    "\n",
    "# Implementing 5-fold cross validation\n",
    "number_of_folds = 5\n",
    "kf = KFold(n_splits=number_of_folds, shuffle=True, random_state=42)\n",
    "\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(df)):\n",
    "\n",
    "  train_data = df.iloc[train_idx]\n",
    "  test_data = df.iloc[test_idx]\n",
    "\n",
    "  overall_train_rating = train_data['Rating'].mean()\n",
    "\n",
    "  ### No Train phase needed ###\n",
    "\n",
    "  ### Evaluation phase ###\n",
    "\n",
    "  # predict rating based on overall training rating\n",
    "  predicteds = [overall_train_rating for row in test_data.itertuples()]\n",
    "  predicteds_normalized = post_process(predicteds)\n",
    "\n",
    "  # calculate RMSE and MAE of final model on test data\n",
    "  rmse = mean_squared_error(test_data['Rating'], predicteds_normalized)\n",
    "  mae = mean_absolute_error(test_data['Rating'], predicteds_normalized)\n",
    "\n",
    "  rmse_list.append(rmse)\n",
    "  mae_list.append(mae)\n",
    "  print(f'RMSE for fold #', fold_idx+1, ': ', rmse)\n",
    "  print(f'MAE for fold #', fold_idx+1, ': ', mae)\n",
    "\n",
    "### Reporting the average error of five models ###\n",
    "print(f'Mean RMSE on all 5 folds: ', np.mean(rmse_list))\n",
    "print(f'Mean MAE on all 5 folds: ', np.mean(mae_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuaAgAX7HBdI"
   },
   "source": [
    "##Conclusion:  \n",
    "The final results are:   \n",
    " 1. Using global average:  \n",
    "    Mean RMSE on all 5 folds:  1.4230040176223635  \n",
    "    Mean MAE on all 5 folds:  0.8709608414659276\n",
    "\n",
    " 2. Using user average:  \n",
    " Mean RMSE on all 5 folds:  1.1547218230176732   \n",
    "Mean MAE on all 5 folds:  0.794360775885776\n",
    "\n",
    "3. Using movie average:    \n",
    "Mean RMSE on all 5 folds:  1.03769116170029  \n",
    "Mean MAE on all 5 folds:  0.7508728185502268  \n",
    "\n",
    "4. linear combination of the three averages:  \n",
    "Mean RMSE on all 5 folds:  0.8935461434633012  \n",
    "Mean MAE on all 5 folds:  0.6745077030556752   \n",
    "\n",
    "\n",
    "We observe that the global average has the worst performance among other naive approaches. Then using user average has a better and lower RMSE compare to the movie average method. And the best performance is for the linear combination algorithm. The linear combination algorithm achieve a somehow acceptable performance with a relatively low runtime cost. It took about one minute to train all 5 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmhMS-4AhVom"
   },
   "source": [
    "# 2. The UV matrix decomposition\n",
    "We have implemented UV decomposition according to chapter 9.4 of MMD. The base idea is that we search for sparse matrices $U$ and $V$ so as to minimize the mean squared error of $M - UV$ (for known values). To this end, we iterate through each element of $U$ and $V$ and set it to the optimal value to minimise the MSE relative to all other current values of $U$ and $V$.\n",
    "\n",
    "In the base train iteration we choose to iterate through all encoding elements of U and V in simple $((U, V), row, column)$ ordering since we have no indication that any optimization ordering biases the training in any way.\n",
    "\n",
    "For the encoding size we have chosen $d = 10$ since we consider 10 a reasonable estimation of pertinent movie tags which may describe genre-like linearly combinable characteristics (e.g. violent, feel-good, cerebral).\n",
    "\n",
    "For preprocessing we choose to subtract from the rating matrix the average scores per users and then the average scores per movies.\n",
    "\n",
    "We chose to initialize matrices $U$ and $V$ with random values normally distributed with mean 0 and standard deviation $\\sqrt{\\sigma(M)}$. The instructions in MMD reccomend using a mean value of $\\mu(M)$ however we argue that this recommendation is not compatible with the preprocessing procedure recommended, specifically because, after preprocessing, the values in $M$ become arbitrarily positive or negative, and thus the encoding parameters also need to be arbitrarily positive or negative, and any judgement about the expected product of two encodings is not applicable.\n",
    "\n",
    "For postprocessing we clip the predicted values to $[1, 5]$ and round them to the nearest integer. We note that none of the preprocessing and postprocessing steps improved the performance of the algorithm, but all of them collectively significantly slowed down its runtime.\n",
    "\n",
    "***Handling unseen data:*** For unseen users or movies we use the average encoding over users in U or movies in V, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1698003473376,
     "user": {
      "displayName": "Victor Nonea",
      "userId": "11296071608438807507"
     },
     "user_tz": -120
    },
    "id": "7Jq32Y-Dx7Cu"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "signed_sqrt = lambda x: sqrt(x) if x >= 0 else -sqrt(-x)\n",
    "root_mean_squared_error = lambda *args, **kwargs: sqrt(mean_squared_error(*args, **kwargs))\n",
    "\n",
    "def relative_diff(a, b):\n",
    "  return 2 * abs(a - b) / abs(a + b)\n",
    "\n",
    "def cond_string(cond, string):\n",
    "  if not cond:\n",
    "    return ''\n",
    "  return string()\n",
    "\n",
    "def post_process(a):\n",
    "  return np.clip(np.round(a), 1, 5)\n",
    "\n",
    "class UVDecomposition:\n",
    "  def init_and_get_train_object(s, df, d=10, preprocessing=True, randomness_factor=1):\n",
    "    fix_init_value = not preprocessing\n",
    "\n",
    "    M = df.pivot_table(index='UserID', columns='MovieID', values='Rating', fill_value=np.NAN)\n",
    "    s.movie_pos = {val: i for val, i in zip(M.columns, range(len(M.columns)))}\n",
    "    s.user_pos = {val: i for val, i in zip(M.index, range(len(M.index)))}\n",
    "\n",
    "    M = np.array(M)\n",
    "    s.no_users, s.no_movies = M.shape\n",
    "\n",
    "    s.d = d\n",
    "\n",
    "    if preprocessing:\n",
    "      s.user_means = np.nanmean(M, axis=1, keepdims=True)\n",
    "      s.user_mean = np.nanmean(s.user_means)\n",
    "      M -= s.user_means\n",
    "      s.movie_means = np.nanmean(M, axis=0, keepdims=True)\n",
    "      s.movie_mean = np.nanmean(s.movie_means)\n",
    "      M -= s.movie_means\n",
    "    else:\n",
    "      s.user_means = np.zeros((M.shape[0], 1))\n",
    "      s.user_mean = 0\n",
    "      s.movie_means = np.zeros((1, M.shape[1]))\n",
    "      s.movie_mean = 0\n",
    "\n",
    "    if fix_init_value:\n",
    "      init_value = sqrt(abs(np.nanmean(M)) / d)\n",
    "    else:\n",
    "      init_value = 0\n",
    "    init_std = randomness_factor * sqrt(np.nanstd(M) / d)\n",
    "    s.U = init_value + np.random.normal(scale=init_std, size=(s.no_users, s.d))\n",
    "    s.V = init_value + np.random.normal(scale=init_std, size=(s.d, s.no_movies))\n",
    "\n",
    "    s.epoch = 0\n",
    "    s.train_err = []\n",
    "    s.val_err = []\n",
    "    s.user_mean_encoding = np.mean(s.U, axis=0)\n",
    "    s.movie_mean_encoding = np.mean(s.V, axis=1)\n",
    "    return M\n",
    "\n",
    "  def train_epoch(s, M, verbose=False, val=None):\n",
    "    s.epoch += 1\n",
    "\n",
    "    for r in range(s.no_users):\n",
    "      for si in range(s.d):\n",
    "        s.U[r, si] += np.nansum(s.V[si] * (M[r] - s.U[r] @ s.V)) / np.sum(s.V[si] ** 2)\n",
    "\n",
    "    for r in range(s.d):\n",
    "      for si in range(s.no_movies):\n",
    "        s.V[r, si] += np.nansum(s.U[:, r] * (M[:, si] - s.U @ s.V[:, si])) / np.sum(s.U[:, r] ** 2)\n",
    "\n",
    "    s.user_mean_encoding = np.mean(s.U, axis=0)\n",
    "    s.movie_mean_encoding = np.mean(s.V, axis=1)\n",
    "\n",
    "    s.train_err.append(s.train_rmse(M))\n",
    "    if val:\n",
    "      s.val_err.append(s.val_rmse(val))\n",
    "\n",
    "    if verbose:\n",
    "      print(f'UVDecomposition: Epoch {s.epoch}, train RMSE {s.train_rmse(M)}' + cond_string(val, lambda: f', validation RMSE {s.val_rmse(val)}'))\n",
    "\n",
    "  def fit(s, M, verbose=True, num_iter=None, val=None, stop_condition='convergence', skip_verbose_step=1):\n",
    "    if verbose:\n",
    "      print(f'UVDecomposition: Initialization, train RMSE {s.train_rmse(M)}' + cond_string(val, lambda: f', validation RMSE {s.val_rmse(val)}'))\n",
    "\n",
    "    if num_iter:\n",
    "      for _ in range(num_iter):\n",
    "        s.train_epoch(M, verbose=verbose and not ((s.epoch + 1) % skip_verbose_step), val=val)\n",
    "      return\n",
    "    if stop_condition == 'convergence':\n",
    "      while len(s.train_err) < 2 or (s.train_err[-1] < s.train_err[-2] and relative_diff(s.train_err[-1], s.train_err[-2]) >= 0.005):\n",
    "        s.train_epoch(M, verbose=verbose and not ((s.epoch + 1) % skip_verbose_step), val=val)\n",
    "      return\n",
    "    if stop_condition == 'overfit':\n",
    "      if val is None:\n",
    "        raise ValueError('Stop condition \"overfit\" called without validation set')\n",
    "      while len(s.val_err) < 2 or s.val_err[-1] < s.val_err[-2] or relative_diff(s.val_err[-1], s.val_err[-2]) < 0.01:\n",
    "        s.train_epoch(M, verbose=verbose and not ((s.epoch + 1) % skip_verbose_step), val=val)\n",
    "      return\n",
    "    raise ValueError(f'Unknown stop condition \"{stop_condition}\"')\n",
    "\n",
    "  def predict(s, users, movies):\n",
    "    return np.array([s.predict_single(user, movie) for user, movie in zip(users, movies)])\n",
    "\n",
    "  def predict_single(s, user, movie):\n",
    "    user_encoding = s.U[s.user_pos[user]] if user in s.user_pos else s.user_mean_encoding\n",
    "    user_mean = s.user_means[s.user_pos[user]] if user in s.user_pos else s.user_mean\n",
    "    movie_encoding = s.V[:, s.movie_pos[movie]] if movie in s.movie_pos else s.movie_mean_encoding\n",
    "    movie_mean = s.movie_means[:, s.movie_pos[movie]] if movie in s.movie_pos else s.movie_mean\n",
    "    return post_process(user_encoding @ movie_encoding + user_mean + movie_mean)\n",
    "\n",
    "  def train_rmse(s, M):\n",
    "    return np.nanmean((M + s.user_means + s.movie_means - post_process(s.U @ s.V + s.user_means + s.movie_means)) ** 2) ** (1 / 2)\n",
    "\n",
    "  def val_rmse(s, val):\n",
    "    (user_val, movie_val), rating_val = val\n",
    "    return root_mean_squared_error(s.predict(user_val, movie_val), rating_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHOJ1L41_0Py"
   },
   "source": [
    "# 5-fold cross-validation\n",
    "For parity with the experiment in Task 3, we have chosen to run each instance of the algorithm for 75 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1698006142652,
     "user": {
      "displayName": "Victor Nonea",
      "userId": "11296071608438807507"
     },
     "user_tz": -120
    },
    "id": "V1xOKo7zBxMP"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "number_of_folds = 5\n",
    "kf = KFold(n_splits=number_of_folds, shuffle=True, random_state=42)\n",
    "\n",
    "def split_dataframe(df):\n",
    "  users = df['UserID']\n",
    "  movies = df['MovieID']\n",
    "  ratings = df['Rating']\n",
    "  return (users, movies), ratings\n",
    "\n",
    "def experiment(single=False, omit_validation=False, **params):\n",
    "  abse_list = []\n",
    "  rmse_list = []\n",
    "  for fold_idx, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "    model = UVDecomposition()\n",
    "\n",
    "    M_train = model.init_and_get_train_object(df.iloc[train_idx], **params)\n",
    "    (user_val, movie_val), rating_val = split_dataframe(df.iloc[val_idx])\n",
    "\n",
    "    if omit_validation:\n",
    "        val = None\n",
    "    else:\n",
    "        val = (user_val, movie_val), rating_val\n",
    "    \n",
    "    model.fit(M_train, verbose=True, val=val, num_iter=75, skip_verbose_step=10)\n",
    "\n",
    "    val_predict = model.predict(user_val, movie_val)\n",
    "\n",
    "    rmse = root_mean_squared_error(val_predict, rating_val)\n",
    "    rmse_list.append(rmse)\n",
    "    print(f'RMSE for fold #', fold_idx+1, ': ', rmse)\n",
    "\n",
    "    abse = mean_absolute_error(val_predict, rating_val)\n",
    "    abse_list.append(abse)\n",
    "    print(f'ABSE for fold #', fold_idx+1, ': ', abse)\n",
    "\n",
    "    if single:\n",
    "      return\n",
    "\n",
    "  print(f'Mean RMSE: ', np.mean(rmse_list))\n",
    "  print(f'Mean ABSE: ', np.mean(abse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDxODvwDCcZd",
    "outputId": "7dd1f592-5a1a-4967-8217-82c4ab9ed5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UVDecomposition: Initialization, train RMSE 1.0048845545430323\n",
      "UVDecomposition: Epoch 10, train RMSE 0.9506037519098967\n",
      "UVDecomposition: Epoch 20, train RMSE 0.9173918826585118\n",
      "UVDecomposition: Epoch 30, train RMSE 0.8910718226573685\n",
      "UVDecomposition: Epoch 40, train RMSE 0.8743598316417551\n",
      "UVDecomposition: Epoch 50, train RMSE 0.8633845161278328\n",
      "UVDecomposition: Epoch 60, train RMSE 0.8550041291405406\n",
      "UVDecomposition: Epoch 70, train RMSE 0.8491630446154963\n",
      "UVDecomposition: Epoch 75, train RMSE 0.8466824961080675\n",
      "RMSE for fold # 1 :  0.9376248612958654\n",
      "ABSE for fold # 1 :  0.6526579418322153\n",
      "UVDecomposition: Initialization, train RMSE 1.0045524408594428\n",
      "UVDecomposition: Epoch 10, train RMSE 0.9490880310177745\n",
      "UVDecomposition: Epoch 20, train RMSE 0.9134826771757573\n",
      "UVDecomposition: Epoch 30, train RMSE 0.88739948633435\n",
      "UVDecomposition: Epoch 40, train RMSE 0.8716578136666325\n",
      "UVDecomposition: Epoch 50, train RMSE 0.8607939646066463\n",
      "UVDecomposition: Epoch 60, train RMSE 0.8529545926988316\n",
      "UVDecomposition: Epoch 70, train RMSE 0.8469481423677361\n",
      "UVDecomposition: Epoch 75, train RMSE 0.8443671071690788\n",
      "RMSE for fold # 2 :  0.936360442412854\n",
      "ABSE for fold # 2 :  0.6516881454894472\n",
      "UVDecomposition: Initialization, train RMSE 1.00493740895483\n",
      "UVDecomposition: Epoch 10, train RMSE 0.9509606208112751\n",
      "UVDecomposition: Epoch 20, train RMSE 0.9161691064372041\n",
      "UVDecomposition: Epoch 30, train RMSE 0.8890007076102008\n",
      "UVDecomposition: Epoch 40, train RMSE 0.8722239616419358\n",
      "UVDecomposition: Epoch 50, train RMSE 0.8609101044893349\n",
      "UVDecomposition: Epoch 60, train RMSE 0.852858617343523\n",
      "UVDecomposition: Epoch 70, train RMSE 0.8466057383370322\n",
      "UVDecomposition: Epoch 75, train RMSE 0.8439525797631912\n",
      "RMSE for fold # 3 :  0.9363123928538101\n",
      "ABSE for fold # 3 :  0.6534977654692514\n",
      "UVDecomposition: Initialization, train RMSE 1.00425630155472\n",
      "UVDecomposition: Epoch 10, train RMSE 0.9508075686945948\n",
      "UVDecomposition: Epoch 20, train RMSE 0.9178911281243027\n",
      "UVDecomposition: Epoch 30, train RMSE 0.8899590801432649\n",
      "UVDecomposition: Epoch 40, train RMSE 0.8730977150092276\n",
      "UVDecomposition: Epoch 50, train RMSE 0.8621375122754185\n",
      "UVDecomposition: Epoch 60, train RMSE 0.8539812714354471\n",
      "UVDecomposition: Epoch 70, train RMSE 0.8478936694438224\n",
      "UVDecomposition: Epoch 75, train RMSE 0.8454855267503233\n",
      "RMSE for fold # 4 :  0.9390097142495873\n",
      "ABSE for fold # 4 :  0.6562654655795562\n",
      "UVDecomposition: Initialization, train RMSE 1.0048204976967012\n",
      "UVDecomposition: Epoch 10, train RMSE 0.9516615435852043\n",
      "UVDecomposition: Epoch 20, train RMSE 0.9179592022530201\n",
      "UVDecomposition: Epoch 30, train RMSE 0.8905725328785234\n",
      "UVDecomposition: Epoch 40, train RMSE 0.8741598724163785\n",
      "UVDecomposition: Epoch 50, train RMSE 0.862679485632951\n",
      "UVDecomposition: Epoch 60, train RMSE 0.8544509023200753\n",
      "UVDecomposition: Epoch 70, train RMSE 0.8479371493753594\n",
      "UVDecomposition: Epoch 75, train RMSE 0.8452948262305265\n",
      "RMSE for fold # 5 :  0.938557093452166\n",
      "ABSE for fold # 5 :  0.6550557135787164\n",
      "Mean RMSE:  0.9375729008528566\n",
      "Mean ABSE:  0.6538330063898373\n"
     ]
    }
   ],
   "source": [
    "experiment(omit_validation=True, d=10, preprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2m38pHJCy8w"
   },
   "source": [
    "Our average RMSE is 0.93 and MAE 0.65."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ylkf9bOh6OA"
   },
   "source": [
    "# 3. The Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onHS4iWvh_oy"
   },
   "source": [
    "## Description of algorithm:  \n",
    "The idea behind matrix factorization (MF) techniques is that we want to approximate the matrix X as the product of two matrices: $ X ≃ UM $.\n",
    "\n",
    "Where $ X $ is a matrix of ratings where rows represent userIDs and columns represent movieIDs. $ U $ is an I × K and $ M $ is a K × J matrix. The $ u_{ik} $ and $ m_{kj} $ values can be considered, reps. the kth feature of the ith user and the jth movie. Our goal in this algorithm is to find best values for each element in $ U $ and $ M $.  \n",
    "\n",
    "In the case of our recommender system problem we want to approximate each unknown element in $ X $ using following formula:  \n",
    "$\\hat{x_{ij}} = \\sum_{k=1}^{K} u_{ik}m_{kj} $.   \n",
    "$ e_{ij} = x_{ij} - \\hat{x_{ij}}$ .   \n",
    "$ SE = \\sum_{i,j \\in R } e_{ij}$.\n",
    "\n",
    "Here $ \\hat{x_{ij}} $ denotes how the ith user would rate the jth movie, according to the model, eij denotes the training error on the (i, j)th example, and SE denotes the total squared training error. The optimal $ U $ and $ M $ minimizes the sum of squared errors only on the known elements of $ X $. In order to minimize SE (which is equivalent to minimize RMSE), we have applied a simple gradient descent method to find a local minimum.\n",
    "\n",
    "We update the weights in the opposite direction of gradient using following formulas:\n",
    "\n",
    "$ {u_{ik}}\\prime = u_{ik} + η · (2e_{ij} · m_{kj} − λ · u_{ik}) $ and   \n",
    "$ {m_{kj}}\\prime = m_{kj} + η · (2e_{ij} · u_{ik} − λ · m_{kj}) $.\n",
    "\n",
    "So this will be the steps of the algorithm:  \n",
    "1. Initialize the weights in $ U $ and $ M $ randomly.\n",
    "Set η and λ to some small positive value.\n",
    "\n",
    "2. Loop until the terminal condition is met (The loop is terminated when the RMSE does not decrease\n",
    "during two iterations.)\n",
    "  - Iterate over each known element of $ X $ on train dataset\n",
    "  - For each $ x_{ij} $, compute $ e_{ij} $\n",
    "  - Update the ith row of $ U $ and the jth column of $ M $ according to equations mentioned for updates.  \n",
    "  - After each iteration on train data, calculate RMSE and check terminal condition\n",
    "\n",
    "3. We will save encoding matrices $ U $ and $ M $ after training of the model finished since we need these encodings for doing the visualizaions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XwaofI6iAS7"
   },
   "source": [
    "## Details of implementation:\n",
    "\n",
    "In this implementation we renumber the overal dataset at first. Then we use **k-fold** from sklearn to find train and test indices for each fold. We repeat the following steps for 5 times in a loop for our cross validation:\n",
    " 1. Initializing X, U and M. We initialize X by using a **df.pivot_table()** using userID as indices, movieID as columns and Ratings as values. We call df.pivot_table() on the whole dataset and fill values which should be in test set with NaN we also feel all empty elements with NaNs. Then we initialize U and M randomly based on the size of X using **np.random.rand()**.\n",
    " 2. After initialization the main part of training gets start. We iterate on each row of train dataframe (x_ij), calculate product of U_ik and M_kj for that coresponding row and calculate error between result of this product and rating value in train sample. We update weights of U_ik and M_kj based on the error in this form:  \n",
    "    U_matrix[index_in_U, :] = U_vector + learning_rate * (((2*error) * M_vector) - (regularization_factor * U_vector))\n",
    "\n",
    "      M_matrix[:, index_in_M] = M_vector + learning_rate * (((2*error) * U_vector) - (regularization_factor * M_vector))\n",
    "\n",
    "3. After one iteration on all rows of train dataset, we calculate RMSE, to check the termination condition. In our experiment we also set a **max_iteration_num = 75** to lessen the computation time. If the termination condition wasn't met, we repeat step 2. We print RMSE after each iteration to keep track of the training process and observe that at the end of each iteration RMSE decrease.\n",
    "\n",
    "4. After termination of the training process, we start evaluation on testdataset. After calculating the predicted values for each test data sample, For this porpuse we wrote a **predict_rating(row)** function which we apply to the test data frame and get predicted results for each data sample(each row). Then we need to do a post process on results. For this porpus we wrote a function **post_process(results)** which round each estimated rating to the nearest integer and also keep results in a range of [1,5]. After doing the post process, we used **mean_squared_error()** and **mean_absolute_error()** functions from sklearn to calculate RMSE amd MAE.\n",
    "\n",
    "\n",
    "***Handling gaps in numbering:*** For handling gaps in numbering on the official dataset, we wrote a function **renumbering(input_df, col)** which renumbers the input dataframe based on UserId and MovieID columns.\n",
    "\n",
    "***Handling gaps in numbering which occurs during cross-validation on train or test dataset:*** These kind of gaps were making trouble in our algorithm since we make $U$ and $M$ matrices based on size and indices of users and movies in $X$. In these cases if we built $X$, $U$ and $M$ just based sampels in  the train dataset the order of indices on this matrices wouldn't mach the order of data samples' indices for test data. For this reason, we initialize $ X $ for training in size of the original dataset and just masked indices which supposed to be used as test data using NaNs (so we just replace NaN for ratings that have to remain unknown in train phase).\n",
    "\n",
    "\n",
    "***Handling unseen data:*** For estimating rating for unseen userID we just return the average rating for the seen movieID, in the same way, for estimating rating for unseen movieID we just return the averahe for the seen userID. We are using a naive approach here, we can also use the approuch we used for handling unseen data in UV matrix decomposition and use the average user encodings for an unssen userID or average movie encoding for an unseen movieID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1002,
     "status": "ok",
     "timestamp": 1697981601994,
     "user": {
      "displayName": "Hedieh Pourghasem",
      "userId": "11017133499432378908"
     },
     "user_tz": -120
    },
    "id": "AfP28bpfipeE",
    "outputId": "6c916e03-913e-43eb-fabe-e32933c95c55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_UserID_id:  6040\n",
      "UserID renumbered\n",
      "max_UserID_id:  6040\n",
      "max_MovieID_id:  3952\n",
      "MovieID renumbered\n",
      "max_MovieID_id:  3706\n"
     ]
    }
   ],
   "source": [
    "# Preprocess to eliminate gaps in numbering (by renumbering UserID and MovieID)\n",
    "def renumbering(input_df, col):\n",
    "  print('max_'+col+'_id: ',  max(df[col]))\n",
    "\n",
    "  # Create a mapping of existing IDs to new IDs\n",
    "  unique_ids = input_df[col].unique()\n",
    "  new_ids = list(range(1, len(unique_ids) + 1))\n",
    "  id_mapping = dict(zip(unique_ids, new_ids))\n",
    "  reverse_id_mapping = dict([(value, key) for key, value in id_mapping.items()])\n",
    "\n",
    "  # Replace the old IDs with the new IDs\n",
    "  input_df[col] = input_df[col].map(id_mapping)\n",
    "\n",
    "  print(f'{col} renumbered')\n",
    "  print('max_'+col+'_id: ', max(df[col]))\n",
    "  return input_df, reverse_id_mapping\n",
    "\n",
    "\n",
    "# renumbering 'UserID' in case there is any gaps\n",
    "df, userID_newtoold_mapping = renumbering(df, 'UserID')\n",
    "\n",
    "\n",
    "# renumbering 'MovieID' in case there is any gaps\n",
    "df, movieID_newtoold_mapping = renumbering(df, 'MovieID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oj0f6P57lLlY"
   },
   "outputs": [],
   "source": [
    "# A function for post processing\n",
    "def post_process(results):\n",
    "  return np.clip(np.round(results), 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1783697,
     "status": "ok",
     "timestamp": 1697987404371,
     "user": {
      "displayName": "Hedieh Pourghasem",
      "userId": "11017133499432378908"
     },
     "user_tz": -120
    },
    "id": "l0LD8C8FlQ4r",
    "outputId": "90e95cfe-ef47-4a44-e9e7-32377646e4fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10 in fold 1, training rmse: 0.8974194322947476\n",
      "iteration 20 in fold 1, training rmse: 0.8553913860959456\n",
      "iteration 30 in fold 1, training rmse: 0.8392393002355556\n",
      "iteration 40 in fold 1, training rmse: 0.8318264082436364\n",
      "iteration 50 in fold 1, training rmse: 0.8276346517837789\n",
      "iteration 60 in fold 1, training rmse: 0.8249219945051585\n",
      "iteration 75 in fold 1, training rmse: 0.8226471447240427\n",
      "%%%%% Finished Training: RMSE on train data for fold # 1  :  0.8226471447240427 %%%%%\n",
      "%%%%% Finished Testing: RMSE on test data for fold # 1 :  0.8421681446896152 %%%%%\n",
      "%%%%% Finished Testing: MAE on test data for fold # 1 :  0.6390408014316994 %%%%%\n",
      "iteration 10 in fold 2, training rmse: 0.898030572851627\n",
      "iteration 20 in fold 2, training rmse: 0.8564660189910339\n",
      "iteration 30 in fold 2, training rmse: 0.8411803767513581\n",
      "iteration 40 in fold 2, training rmse: 0.8337989815873477\n",
      "iteration 50 in fold 2, training rmse: 0.829475577597213\n",
      "iteration 60 in fold 2, training rmse: 0.8266865743928298\n",
      "iteration 70 in fold 2, training rmse: 0.8248629081522708\n",
      "iteration 75 in fold 2, training rmse: 0.824181594295318\n",
      "%%%%% Finished Training: RMSE on train data for fold # 2  :  0.824181594295318 %%%%%\n",
      "%%%%% Finished Testing: RMSE on test data for fold # 2 :  0.8499515101828616 %%%%%\n",
      "%%%%% Finished Testing: MAE on test data for fold # 2 :  0.6425150718349146 %%%%%\n",
      "iteration 10 in fold 3, training rmse: 0.8989082725800662\n",
      "iteration 20 in fold 3, training rmse: 0.8558617040178256\n",
      "iteration 30 in fold 3, training rmse: 0.8403546658033142\n",
      "iteration 40 in fold 3, training rmse: 0.8330987239829925\n",
      "iteration 50 in fold 3, training rmse: 0.8289948125755372\n",
      "iteration 60 in fold 3, training rmse: 0.8265316058337974\n",
      "iteration 70 in fold 3, training rmse: 0.824588631451885\n",
      "iteration 75 in fold 3, training rmse: 0.8237652534202362\n",
      "%%%%% Finished Training: RMSE on train data for fold # 3  :  0.8237652534202362 %%%%%\n",
      "%%%%% Finished Testing: RMSE on test data for fold # 3 :  0.8470521190549984 %%%%%\n",
      "%%%%% Finished Testing: MAE on test data for fold # 3 :  0.6413553153837694 %%%%%\n",
      "iteration 10 in fold 4, training rmse: 0.8964811666269727\n",
      "iteration 20 in fold 4, training rmse: 0.855993308239902\n",
      "iteration 30 in fold 4, training rmse: 0.8403258842200654\n",
      "iteration 40 in fold 4, training rmse: 0.832494190086123\n",
      "iteration 50 in fold 4, training rmse: 0.8285939469636697\n",
      "iteration 60 in fold 4, training rmse: 0.8260433160233555\n",
      "iteration 75 in fold 4, training rmse: 0.8234180067903525\n",
      "%%%%% Finished Training: RMSE on train data for fold # 4  :  0.8234180067903525 %%%%%\n",
      "%%%%% Finished Testing: RMSE on test data for fold # 4 :  0.8505706330202308 %%%%%\n",
      "%%%%% Finished Testing: MAE on test data for fold # 4 :  0.6429631925455281 %%%%%\n",
      "iteration 10 in fold 5, training rmse: 0.8978532553693104\n",
      "iteration 20 in fold 5, training rmse: 0.8558451067282847\n",
      "iteration 21 in fold 5, training rmse: 0.8534176661180879\n",
      "iteration 30 in fold 5, training rmse: 0.8404099072538657\n",
      "iteration 40 in fold 5, training rmse: 0.8332452012362426\n",
      "iteration 50 in fold 5, training rmse: 0.8288163861702638\n",
      "iteration 60 in fold 5, training rmse: 0.826190056425004\n",
      "iteration 70 in fold 5, training rmse: 0.8245206695909181\n",
      "iteration 75 in fold 5, training rmse: 0.8237768754395323\n",
      "%%%%% Finished Training: RMSE on train data for fold # 5  :  0.8237768754395323 %%%%%\n",
      "%%%%% Finished Testing: RMSE on test data for fold # 5 :  0.8509005653840963 %%%%%\n",
      "%%%%% Finished Testing: MAE on test data for fold # 5 :  0.6440729650421664 %%%%%\n",
      "Mean RMSE on all 5 folds (on test data):  0.8481285944663606\n",
      "Mean MAE on all 5 folds (on test data):  0.6419894692476156\n"
     ]
    }
   ],
   "source": [
    "### Setting hyperparameters ###\n",
    "num_factor = 10\n",
    "learning_rate = 0.005\n",
    "regularization_factor = 0.05\n",
    "max_num_iter = 75\n",
    "number_of_folds = 5\n",
    "\n",
    "\n",
    "# Implementing 5-fold cross validation\n",
    "kf = KFold(n_splits=number_of_folds, shuffle=True, random_state=42)\n",
    "\n",
    "train_indices_list = []\n",
    "test_indices_list = []\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(df)):\n",
    "  train_data = df.iloc[train_idx]\n",
    "  train_users = [row.UserID for row in train_data.itertuples()]\n",
    "  train_movies = [row.MovieID for row in train_data.itertuples()]\n",
    "  test_data = df.iloc[test_idx]\n",
    "\n",
    "  ### Train Phase ###\n",
    "  t = copy.deepcopy(df)\n",
    "  t.loc[test_idx, 'Rating'] = np.nan\n",
    "  X_matrix = t.pivot_table(index='UserID', columns='MovieID', values='Rating', fill_value=np.NAN, dropna = False)\n",
    "  X_matrix = np.array(X_matrix)\n",
    "\n",
    "  number_of_users, number_of_movies = X_matrix.shape\n",
    "\n",
    "  # U dimension is I*K (k = num_factors, I = number of users)\n",
    "  U_matrix = np.random.rand(number_of_users, num_factor)\n",
    "\n",
    "  # M dimension is K*J (k = num_factors, I = number of movies)\n",
    "  M_matrix = np.random.rand(num_factor, number_of_movies)\n",
    "\n",
    "  prev_U_matrix = None\n",
    "  prev_M_matrix = None\n",
    "\n",
    "  current_RMSE = np.sqrt(np.nanmean((X_matrix - U_matrix @ M_matrix) ** 2))\n",
    "  prev_RMSE = np.math.inf\n",
    "  iter_num = 0\n",
    "\n",
    "  # Train loop\n",
    "  while (current_RMSE < prev_RMSE and iter_num < max_num_iter):\n",
    "    prev_U_matrix = U_matrix\n",
    "    prev_M_matrix = M_matrix\n",
    "    for row in train_data.itertuples():\n",
    "      index_in_U = row.UserID - 1\n",
    "      index_in_M = row.MovieID - 1\n",
    "      U_vector = U_matrix[index_in_U, :] #U_ik\n",
    "      M_vector = M_matrix[:, index_in_M] #M_kj\n",
    "\n",
    "      # approximated X_ij\n",
    "      result = np.dot(U_vector, M_vector)\n",
    "\n",
    "      # calculating error e_ij\n",
    "      error = row.Rating - result\n",
    "\n",
    "      # update the ith row of U and jth column of M according to error gradient and using a gradient decent approuch with regularization\n",
    "      U_matrix[index_in_U, :] = U_vector + learning_rate * (((2*error) * M_vector) - (regularization_factor * U_vector))\n",
    "      M_matrix[:, index_in_M] = M_vector + learning_rate * (((2*error) * U_vector) - (regularization_factor * M_vector))\n",
    "\n",
    "    # calculating RMSE\n",
    "    new_RMSE = np.sqrt(np.nanmean((X_matrix - post_process(U_matrix @ M_matrix)) ** 2))\n",
    "    prev_RMSE = current_RMSE\n",
    "    current_RMSE = new_RMSE\n",
    "    iter_num += 1\n",
    "    print(f'iteration {iter_num} in fold {fold_idx+1}, training rmse: {current_RMSE}')\n",
    "\n",
    "  # train_RMSE = np.sqrt(np.nanmean((X_matrix - prev_U_matrix @ prev_M_matrix) ** 2))\n",
    "  print(f'%%%%% Finished Training: RMSE on train data for fold #', fold_idx+1, ' : ', current_RMSE, '%%%%%')\n",
    "\n",
    "  ### save trained encodings ###\n",
    "  movieIDs = np.array([movieID_newtoold_mapping[index+1] for index in np.arange(number_of_movies)])\n",
    "  userIDs = np.array([userID_newtoold_mapping[index+1] for index in np.arange(number_of_users)])\n",
    "\n",
    "  np.save(os.path.join('/content/', 'user_encodings_MF_'+str(fold_idx+1)), np.concatenate((userIDs.reshape(-1, 1), prev_U_matrix), axis=1))\n",
    "  np.save(os.path.join('/content/', 'movie_encodings_MF_'+str(fold_idx+1)), np.concatenate((movieIDs.reshape(-1, 1), np.transpose(prev_M_matrix)), axis=1))\n",
    "\n",
    "\n",
    "  ### Test Phase ###\n",
    "  predicted = []\n",
    "  movieMean = train_data.groupby('MovieID')['Rating'].mean()\n",
    "  userMean = train_data.groupby('UserID')['Rating'].mean()\n",
    "  overall_mean = train_data['Rating'].mean()\n",
    "\n",
    "  def predict_rating(row):\n",
    "    if row['UserID'] in userMean and row['MovieID'] in movieMean:\n",
    "      # Predict using your model\n",
    "      index_in_U = row.UserID - 1\n",
    "      index_in_M = row.MovieID - 1\n",
    "      U_vector = U_matrix[index_in_U, :] #U_ik\n",
    "      M_vector = M_matrix[:, index_in_M] #M_kj\n",
    "      # approximated X_ij\n",
    "      result = np.dot(U_vector, M_vector)\n",
    "      return result\n",
    "    elif row['UserID'] in userMean:\n",
    "        # Predict using movie mean\n",
    "        return movieMean.get(row['MovieID'], overall_mean)\n",
    "    elif row['MovieID'] in movieMean:\n",
    "        # Predict using user mean\n",
    "        return userMean.get(row['UserID'], overall_mean)\n",
    "    else:\n",
    "        # Both user and movie are unseen, predict using overall mean\n",
    "        return overall_mean\n",
    "\n",
    "  output = test_data.apply(predict_rating, axis=1)\n",
    "\n",
    "  normalized_output = post_process(output)\n",
    "\n",
    "  test_RMSE = mean_squared_error(test_data['Rating'], normalized_output)\n",
    "  test_MAE = mean_absolute_error(test_data['Rating'], normalized_output)\n",
    "\n",
    "  print(f'%%%%% Finished Testing: RMSE on test data for fold #', fold_idx+1, ': ', test_RMSE, '%%%%%')\n",
    "  print(f'%%%%% Finished Testing: MAE on test data for fold #', fold_idx+1, ': ', test_MAE, '%%%%%')\n",
    "\n",
    "  rmse_list.append(test_RMSE)\n",
    "  mae_list.append(test_MAE)\n",
    "\n",
    "### Reporting the average error of five models ###\n",
    "print(f'Mean RMSE on all 5 folds (on test data): ', np.mean(rmse_list))\n",
    "print(f'Mean MAE on all 5 folds (on test data): ', np.mean(mae_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BAn3krTiHVW"
   },
   "source": [
    "##Conclusion:  \n",
    "The final results are:   \n",
    "Mean RMSE on all 5 folds:  0.84812859446636062.  \n",
    "Mean MAE on all 5 folds:  0.6419894692476156.   \n",
    "We observe that this algorithm achieve a better performance in comparision to the naive approach while it has a significantly longer runtime. It took about two hours to train and evaluate all 5 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjYNsXUViJty"
   },
   "source": [
    "# Final Conclusion:\n",
    "The best performance is achieved by the Matrix Factorization algorithm, with a significant improvement to all other methods, RMSE 0.84, MAE 0.64.\n",
    "\n",
    "The best of the naive approaches, the linear combination of averages, achieves competitive results, RMSE 0.89, MAE 0.67.\n",
    "\n",
    "UV decomposition achieves better results than the first 3 naive approaches, but performs slightly worse than linear combination of averages and Matrix Factorization, with RMSE 0.93 and MAE 0.65. We suspect this is because the UV decomposition lacks any regularization mechanism, whereas MF includes explicit regularization, and the linear combination of averages has only 3 parameters. Supporting this idea we note that the train RMSE for UV decomposition is about 0.84, on par with the train performance of MF, 0.82."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM1lsCpWRqxyY+5wULTX+vM",
   "collapsed_sections": [
    "lmhMS-4AhVom"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
